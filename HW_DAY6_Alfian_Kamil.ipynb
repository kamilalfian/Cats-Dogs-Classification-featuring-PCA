{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5IZZLfOjeqT"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "This is a program created to classify between cats and dogs, with and without applying PCA. This program will be executed by defining these prerequisite functions:\n",
        "\n",
        "1. Data preparing (with and without PCA)\n",
        "2. Data Augmentaton and Data Preprocessing\n",
        "3. Build Model\n",
        "4. Compile Model\n",
        "5. Plot Tensorboard\n",
        "6. Train Model and Predict\n",
        "7. Create confusion matrix\n",
        "\n",
        "After those, we will run each functions in order using PCA and without using PCA. By the end of this project, the training speed and model performance of those two will be compared.\n",
        "\n",
        "NOTE: Simply run all to achieve all the objectives in this project."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iI6iFGydlESk"
      },
      "source": [
        "# 1. Data preparing (with and without PCA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GqKSbH3jgYZn"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import shutil\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from numpy import asarray\n",
        "\n",
        "def data_preparing():\n",
        "  # Refresh data everytime this function is started\n",
        "  if os.path.exists('/tmp/cats_and_dogs_filtered'):\n",
        "    shutil.rmtree('/tmp/cats_and_dogs_filtered')\n",
        "  # Load data\n",
        "  !wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "    -O /tmp/cats_and_dogs_filtered.zip\n",
        "  local_zip = '/tmp/cats_and_dogs_filtered.zip'\n",
        "  zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "  zip_ref.extractall('/tmp')\n",
        "  zip_ref.close()\n",
        "  base_dir = '/tmp/cats_and_dogs_filtered'\n",
        "  # Create the directory path\n",
        "  train_dir = os.path.join(base_dir, 'train')\n",
        "  validation_dir = os.path.join(base_dir, 'validation')\n",
        "  test_dir = os.path.join(base_dir, 'test')\n",
        "  # Directory with our training cat pictures\n",
        "  train_cats_dir = os.path.join(train_dir, 'cats')\n",
        "  # Directory with our training dog pictures\n",
        "  train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "  # Directory with our validation cat pictures\n",
        "  validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
        "  # Directory with our validation dog pictures\n",
        "  validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
        "  # Directory with our test cat pictures\n",
        "  test_cats_dir = os.path.join(test_dir, 'cats')\n",
        "  # Directory with our test dogs pictures\n",
        "  test_dogs_dir = os.path.join(test_dir, 'dogs')\n",
        "  # Create the test directories if they don't exist\n",
        "  os.makedirs(test_cats_dir, exist_ok=True)\n",
        "  os.makedirs(test_dogs_dir, exist_ok=True)\n",
        "  # Move 200 cat images to the test_cats_dir\n",
        "  cat_filenames = os.listdir(train_cats_dir)[:200]\n",
        "  for cat_filename in cat_filenames:\n",
        "    src = os.path.join(train_cats_dir, cat_filename)\n",
        "    dst = os.path.join(test_cats_dir, cat_filename)\n",
        "    shutil.move(src, dst)\n",
        "  # Move 200 dog images to the test_dogs_dir\n",
        "  dog_filenames = os.listdir(train_dogs_dir)[:200]\n",
        "  for dog_filename in dog_filenames:\n",
        "    src = os.path.join(train_dogs_dir, dog_filename)\n",
        "    dst = os.path.join(test_dogs_dir, dog_filename)\n",
        "    shutil.move(src, dst)\n",
        "  return train_dir, validation_dir, test_dir\n",
        "\n",
        "def data_preparing_with_pca(n_components):\n",
        "  # Refresh data everytime this function is started\n",
        "  if os.path.exists('/tmp/cats_and_dogs_filtered'):\n",
        "    shutil.rmtree('/tmp/cats_and_dogs_filtered')\n",
        "  # Load data\n",
        "  !wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "    -O /tmp/cats_and_dogs_filtered.zip\n",
        "  local_zip = '/tmp/cats_and_dogs_filtered.zip'\n",
        "  zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "  zip_ref.extractall('/tmp')\n",
        "  zip_ref.close()\n",
        "  base_dir = '/tmp/cats_and_dogs_filtered'\n",
        "  # Create separate PCA instances for each channel\n",
        "  pca_red = PCA(n_components)\n",
        "  pca_green = PCA(n_components)\n",
        "  pca_blue = PCA(n_components)\n",
        "  # Create the directory path\n",
        "  train_dir = os.path.join(base_dir, 'train')\n",
        "  validation_dir = os.path.join(base_dir, 'validation')\n",
        "  test_dir = os.path.join(base_dir, 'test')\n",
        "  # Directory with our training cat pictures\n",
        "  train_cats_dir = os.path.join(train_dir, 'cats')\n",
        "  # Directory with our training dog pictures\n",
        "  train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "  # Directory with our validation cat pictures\n",
        "  validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
        "  # Directory with our validation dog pictures\n",
        "  validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
        "  # Directory with our test cat pictures\n",
        "  test_cats_dir = os.path.join(test_dir, 'cats')\n",
        "  # Directory with our test dogs pictures\n",
        "  test_dogs_dir = os.path.join(test_dir, 'dogs')\n",
        "  # Load the cat/cog training/validation images, apply PCA, and save\n",
        "  image_file_path_train_cats = [os.path.join(train_cats_dir, filename) for filename in os.listdir(train_cats_dir)]\n",
        "  image_file_path_validation_cats = [os.path.join(validation_cats_dir, filename) for filename in os.listdir(validation_cats_dir)]\n",
        "  image_file_path_train_dogs = [os.path.join(train_dogs_dir, filename) for filename in os.listdir(train_dogs_dir)]\n",
        "  image_file_path_validation_dogs = [os.path.join(validation_dogs_dir, filename) for filename in os.listdir(validation_dogs_dir)]\n",
        "  for (path,dir) in zip([image_file_path_train_cats,image_file_path_validation_cats,image_file_path_train_dogs,\n",
        "                    image_file_path_validation_dogs],\n",
        "                     [train_cats_dir,validation_cats_dir,train_dogs_dir,validation_dogs_dir]):\n",
        "    for i, image_path in enumerate(path):\n",
        "      # Load the original image\n",
        "      original_image = Image.open(image_path)\n",
        "      # Separate the image into its RGB channels\n",
        "      red_channel, green_channel, blue_channel = original_image.split()\n",
        "      # Convert each channel to NumPy arrays\n",
        "      red_channel = np.array(red_channel)\n",
        "      green_channel = np.array(green_channel)\n",
        "      blue_channel = np.array(blue_channel)\n",
        "      # Apply PCA to the red channel\n",
        "      pca_red = pca_red.fit(red_channel)\n",
        "      red_channel = pca_red.transform(red_channel)\n",
        "      red_channel = pca_red.inverse_transform(red_channel)\n",
        "      # Apply PCA to the green channel\n",
        "      pca_green = pca_green.fit(green_channel)\n",
        "      green_channel = pca_green.transform(green_channel)\n",
        "      green_channel = pca_green.inverse_transform(green_channel)\n",
        "      # Apply PCA to the blue channel\n",
        "      pca_blue = pca_blue.fit(blue_channel)\n",
        "      blue_channel = pca_blue.transform(blue_channel)\n",
        "      blue_channel = pca_blue.inverse_transform(blue_channel)\n",
        "      # Create an image from the reconstructed channels\n",
        "      reconstructed_image = Image.merge(\"RGB\", [\n",
        "          Image.fromarray(red_channel.astype(np.uint8)),\n",
        "          Image.fromarray(green_channel.astype(np.uint8)),\n",
        "          Image.fromarray(blue_channel.astype(np.uint8))\n",
        "      ])\n",
        "      # Define the new file path for the PCA-reversed image\n",
        "      new_image_path = os.path.join(dir, f'reconstructed_{i}.jpg')\n",
        "      # Save the PCA-reversed image as JPEG\n",
        "      reconstructed_image.save(new_image_path)\n",
        "    # Delete original images\n",
        "    for image_path in path:\n",
        "      os.remove(image_path)\n",
        "  # Create the test directories if they don't exist\n",
        "  os.makedirs(test_cats_dir, exist_ok=True)\n",
        "  os.makedirs(test_dogs_dir, exist_ok=True)\n",
        "  # Move 200 cat images to the test_cats_dir\n",
        "  cat_filenames = os.listdir(train_cats_dir)[:200]\n",
        "  for cat_filename in cat_filenames:\n",
        "    src = os.path.join(train_cats_dir, cat_filename)\n",
        "    dst = os.path.join(test_cats_dir, cat_filename)\n",
        "    shutil.move(src, dst)\n",
        "  # Move 200 dog images to the test_dogs_dir\n",
        "  dog_filenames = os.listdir(train_dogs_dir)[:200]\n",
        "  for dog_filename in dog_filenames:\n",
        "    src = os.path.join(train_dogs_dir, dog_filename)\n",
        "    dst = os.path.join(test_dogs_dir, dog_filename)\n",
        "    shutil.move(src, dst)\n",
        "  return train_dir, validation_dir, test_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nV-atIVhlT6o"
      },
      "source": [
        "# 2. Data Augmentation and Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dg2FwJE_6tx8"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# First create data augmentation object for better training quality (apply this to train_datagen only)\n",
        "data_augmentation = Sequential(\n",
        "    [\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(0.1),\n",
        "        layers.RandomZoom(0.1),\n",
        "        layers.RandomContrast(factor=0.1),\n",
        "        layers.RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
        "    ],\n",
        "    name=\"img_augmentation\"\n",
        ")\n",
        "\n",
        "def data_preprocessing(train_dir,validation_dir,test_dir):\n",
        "  # All images will be rescaled by 1./255, apply data_augmentation to train_datagen\n",
        "  train_datagen = ImageDataGenerator(rescale=1./255,preprocessing_function=data_augmentation)\n",
        "  val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "  test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "  # Flow training images in batches of 20 using train_datagen generator\n",
        "  train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,  # This is the source directory for training images\n",
        "        target_size=(384, 384),  # All images will be resized to 384x384\n",
        "        batch_size=20,\n",
        "        # Since we use binary_crossentropy loss, we need binary labels\n",
        "        class_mode='binary')\n",
        "  # Flow validation images in batches of 20 using val_datagen generator\n",
        "  validation_generator = val_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(384, 384),\n",
        "        batch_size=20,\n",
        "        class_mode='binary')\n",
        "  # Flow test images in batches of 20 using test_datagen generator\n",
        "  test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,  # This is the source directory for test images\n",
        "    target_size=(384, 384),  # All images will be resized to 384x384 (same as training and validation)\n",
        "    batch_size=20,  # Use a batch size that matches your training and validation generators\n",
        "    class_mode=None,  # Since this is the test set, you don't need class labels\n",
        "    shuffle=False  # Set to False to ensure the order of predictions matches the order of test images\n",
        "    )\n",
        "  return train_generator, validation_generator, test_generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gO5dNbgNlalI"
      },
      "source": [
        "#3. Build Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xlvNi9Fb8agf"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dropout, Dense, Reshape\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "def build_model():\n",
        "  model = tf.keras.Sequential([\n",
        "    hub.KerasLayer(\"https://www.kaggle.com/models/google/efficientnet-v2/frameworks/TensorFlow2/variations/imagenet1k-s-classification/versions/2\", trainable=False),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')  # For binary classification\n",
        "    ])\n",
        "  model.build([None,384,384,3])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4Va83U1lidE"
      },
      "source": [
        "#4. Compile Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "DsIMYjCNsqlS"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "def compile_model(model):\n",
        "  model.compile(loss='binary_crossentropy',\n",
        "              optimizer=Adam(learning_rate=0.001),\n",
        "              metrics=['acc'])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osHi24Ptlp2D"
      },
      "source": [
        "#5. Plot Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "TNUP03XT2HTU"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from datetime import datetime\n",
        "\n",
        "def plot_tensorboard(base_log_dir):\n",
        "    current_time = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "    log_dir = f\"{base_log_dir}/{current_time}\"\n",
        "    tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "    return tensorboard_callback"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71uLBiUslyOQ"
      },
      "source": [
        "#6. Train Model and Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4DHxdgGu2fkq"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Define the EarlyStopping callback\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',  # Monitor validation loss\n",
        "    patience=3,           # Number of epochs with no improvement after which training will be stopped\n",
        "    restore_best_weights=True  # Restore the model weights from the epoch with the best validation loss\n",
        ")\n",
        "\n",
        "def train_model_predict():\n",
        "  history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=80, #total images(1600)=steps(80)*batch size(20)\n",
        "    epochs=15,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=50, #total images(1000)=steps(50)*batch size(20)\n",
        "    verbose=1,\n",
        "    callbacks=[tensorboard_callback,early_stopping])  # Add this line\n",
        "  predictions = model.predict_generator(test_generator, steps=len(test_generator), verbose=1)\n",
        "  return predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrJ__09Vl3V3"
      },
      "source": [
        "#7. Create Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ZT2GPU5j3MuA"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "def create_confusionmatrix():\n",
        "  # Assuming you have actual labels for your test data (true_labels)\n",
        "  true_labels = test_generator.classes\n",
        "  # Convert the predicted probabilities to binary predictions (0 or 1)\n",
        "  predicted_labels = (predictions > 0.5).astype(int)\n",
        "  # Create the confusion matrix\n",
        "  confusion = confusion_matrix(true_labels, predicted_labels)\n",
        "  # Print the confusion matrix\n",
        "  print(\"Confusion Matrix:\")\n",
        "  print(confusion)\n",
        "  # You can also print a classification report for more metrics\n",
        "  print(\"Classification Report:\")\n",
        "  print(classification_report(true_labels, predicted_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuIePBcZl9a6"
      },
      "source": [
        "#Executing program without PCA\n",
        "This will execute all the prerequisite functions without applying PCA on the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jaBJS4yk4Iio",
        "outputId": "78b3ac8b-5a95-4438-da32-fac5c049e639"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-04 19:57:31--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.10.207, 142.251.12.207, 172.217.194.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.10.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68606236 (65M) [application/zip]\n",
            "Saving to: ‘/tmp/cats_and_dogs_filtered.zip’\n",
            "\n",
            "/tmp/cats_and_dogs_ 100%[===================>]  65.43M  20.4MB/s    in 3.9s    \n",
            "\n",
            "2023-11-04 19:57:35 (16.8 MB/s) - ‘/tmp/cats_and_dogs_filtered.zip’ saved [68606236/68606236]\n",
            "\n",
            "Found 1600 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n",
            "Found 400 images belonging to 2 classes.\n",
            "Epoch 1/15\n",
            "80/80 [==============================] - 121s 1s/step - loss: 0.0578 - acc: 0.9819 - val_loss: 0.0284 - val_acc: 0.9950\n",
            "Epoch 2/15\n",
            "80/80 [==============================] - 96s 1s/step - loss: 0.0284 - acc: 0.9919 - val_loss: 0.0396 - val_acc: 0.9920\n",
            "Epoch 3/15\n",
            "80/80 [==============================] - 97s 1s/step - loss: 0.0179 - acc: 0.9937 - val_loss: 0.0204 - val_acc: 0.9960\n",
            "Epoch 4/15\n",
            "80/80 [==============================] - 108s 1s/step - loss: 0.0121 - acc: 0.9956 - val_loss: 0.0173 - val_acc: 0.9960\n",
            "Epoch 5/15\n",
            "80/80 [==============================] - 97s 1s/step - loss: 0.0052 - acc: 0.9981 - val_loss: 0.0226 - val_acc: 0.9960\n",
            "Epoch 6/15\n",
            "80/80 [==============================] - 95s 1s/step - loss: 0.0061 - acc: 0.9975 - val_loss: 0.0314 - val_acc: 0.9950\n",
            "Epoch 7/15\n",
            "80/80 [==============================] - 96s 1s/step - loss: 0.0101 - acc: 0.9969 - val_loss: 0.0256 - val_acc: 0.9950\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-d964d65577dc>:19: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  predictions = model.predict_generator(test_generator, steps=len(test_generator), verbose=1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 5s 203ms/step\n",
            "Confusion Matrix:\n",
            "[[200   0]\n",
            " [  3 197]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       200\n",
            "           1       1.00      0.98      0.99       200\n",
            "\n",
            "    accuracy                           0.99       400\n",
            "   macro avg       0.99      0.99      0.99       400\n",
            "weighted avg       0.99      0.99      0.99       400\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n",
              "            url.searchParams.set('tensorboardColab', 'true');\n",
              "            const iframe = document.createElement('iframe');\n",
              "            iframe.src = url;\n",
              "            iframe.setAttribute('width', '100%');\n",
              "            iframe.setAttribute('height', '800');\n",
              "            iframe.setAttribute('frameborder', 0);\n",
              "            document.body.appendChild(iframe);\n",
              "        })();\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# This cell executes all the functions that will become the scoring criteria without applying PCA\n",
        "\n",
        "train_dir, validation_dir, test_dir=data_preparing()\n",
        "train_generator, validation_generator, test_generator=data_preprocessing(train_dir,validation_dir,test_dir)\n",
        "model=build_model()\n",
        "model=compile_model(model)\n",
        "tensorboard_callback=plot_tensorboard(\"logs/\")\n",
        "predictions=train_model_predict()\n",
        "create_confusionmatrix()\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZrMzh3SmNBo"
      },
      "source": [
        "#Executing program with PCA\n",
        "This will execute all the prerequisite functions by applying PCA on the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "65eu3aprjTiq",
        "outputId": "cc413651-c395-4afc-d333-e35dc713de38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-04 20:20:13--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.170.207, 142.251.175.207, 74.125.24.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.170.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68606236 (65M) [application/zip]\n",
            "Saving to: ‘/tmp/cats_and_dogs_filtered.zip’\n",
            "\n",
            "/tmp/cats_and_dogs_ 100%[===================>]  65.43M  19.8MB/s    in 4.0s    \n",
            "\n",
            "2023-11-04 20:20:18 (16.4 MB/s) - ‘/tmp/cats_and_dogs_filtered.zip’ saved [68606236/68606236]\n",
            "\n",
            "Found 1600 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n",
            "Found 400 images belonging to 2 classes.\n",
            "Epoch 1/15\n",
            "80/80 [==============================] - 111s 1s/step - loss: 0.3777 - acc: 0.8200 - val_loss: 0.1659 - val_acc: 0.9400\n",
            "Epoch 2/15\n",
            "80/80 [==============================] - 95s 1s/step - loss: 0.3070 - acc: 0.8525 - val_loss: 0.1463 - val_acc: 0.9450\n",
            "Epoch 3/15\n",
            "80/80 [==============================] - 104s 1s/step - loss: 0.2834 - acc: 0.8706 - val_loss: 0.1491 - val_acc: 0.9460\n",
            "Epoch 4/15\n",
            "80/80 [==============================] - 95s 1s/step - loss: 0.2551 - acc: 0.8906 - val_loss: 0.1696 - val_acc: 0.9430\n",
            "Epoch 5/15\n",
            "80/80 [==============================] - 95s 1s/step - loss: 0.2371 - acc: 0.8906 - val_loss: 0.1820 - val_acc: 0.9350\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-d964d65577dc>:19: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  predictions = model.predict_generator(test_generator, steps=len(test_generator), verbose=1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 6s 214ms/step\n",
            "Confusion Matrix:\n",
            "[[193   7]\n",
            " [  7 193]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.96      0.96       200\n",
            "           1       0.96      0.96      0.96       200\n",
            "\n",
            "    accuracy                           0.96       400\n",
            "   macro avg       0.96      0.96      0.96       400\n",
            "weighted avg       0.96      0.96      0.96       400\n",
            "\n",
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n",
              "            url.searchParams.set('tensorboardColab', 'true');\n",
              "            const iframe = document.createElement('iframe');\n",
              "            iframe.src = url;\n",
              "            iframe.setAttribute('width', '100%');\n",
              "            iframe.setAttribute('height', '800');\n",
              "            iframe.setAttribute('frameborder', 0);\n",
              "            document.body.appendChild(iframe);\n",
              "        })();\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# This cell executes all the functions that will become the scoring criteria by applying PCA\n",
        "\n",
        "train_dir, validation_dir, test_dir=data_preparing_with_pca(0.95) # let's try retaining 95% of the n_components\n",
        "train_generator, validation_generator, test_generator=data_preprocessing(train_dir,validation_dir,test_dir)\n",
        "model=build_model()\n",
        "model=compile_model(model)\n",
        "tensorboard_callback=plot_tensorboard(\"logs/\")\n",
        "predictions=train_model_predict()\n",
        "create_confusionmatrix()\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-woNCbc3NBF"
      },
      "source": [
        "#Conclusion\n",
        "\n",
        "Classification of cats and dogs images without/with using PCA at 95 % variance ratio retention doesn't differ in training speed. In addition, slight decline of model performance was observed where as without using PCA the model can easily achieve 98 %-100 % score across the classification report with only 3 images mistakenly being a false negative while with using PCA gives roughly 96 % score across classification report and roughly 7 images in false positive/negative each.\n",
        "\n",
        "One possible explanation for this is because the image dataset is clean to begin with that further PCA will only unnecessarily drop principle components and doesn't contribute anything to the cleaning of the images."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}